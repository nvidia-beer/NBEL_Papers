# 2021: Data-Driven Artificial and Spiking Neural Networks for Inverse Kinematics in Neurorobotics

## Paper Info

**Authors:** Volinski et al.  
**Publication:** Patterns (Cell Press), Jan 2022  
**Link:** [PDF](https://static1.squarespace.com/static/555995e2e4b0c9f3319aaa47/t/61994bfcbd361e425e78e3fb/1637436425748/2021+Volinski+et+al.pdf)

---

## Overview

This paper tackles inverse kinematics (IK) for a 6-DOF robotic arm using spiking neural networks (SNNs) on Intel's Loihi neuromorphic chip. The goal is to achieve energy-efficient, biologically-inspired control that actually runs on hardware—not just in simulation.

### The Problem

Traditional IK methods (like Jacobian pseudo-inverse) are computationally expensive and don't map well to neuromorphic hardware. We need a brain-like approach that's both accurate and energy-efficient.

### Key Math

**Jacobian-based IK:**

The relationship between joint velocities $\dot{q}$ and end-effector velocities $\dot{x}$:

$$
\dot{x} = J(q)\dot{q}
$$

To solve for joint velocities: $\dot{q} = J^+ \dot{x}$ (using Moore-Penrose pseudoinverse)

**Two main approaches:**
- Standard: $\Delta \theta = J^{\dagger} \vec{e}$
- Dampened Least Squares (DLS): $\Delta \theta = \left(J^T J + \lambda^2 I\right)^{-1} J^T \vec{e}$ (better for singularities)

**Neural Engineering Framework (NEF):**

The NEF paradigm has three components:

1. **Encoding:** Neurons represent continuous values through firing rates
   $$a_i(x) = G_i[\alpha_i \cdot x + J_{\text{bias},i}]$$

2. **Decoding:** Reconstruct values from neural activity
   $$\hat{x} = \sum_i d_i a_i(x)$$

3. **Learning:** PES (Prescribed Error Sensitivity) rule for online adaptation
   $$\Delta d = \kappa e a$$

### What They Did

**Hardware:** ViperX 300 6-DOF arm  
**Training data:** 200k samples (position → joint angles)  
**Target:** Sub-millimeter accuracy (< 1mm)

**Tested Networks:**
1. **ANNs:** FC networks (5 layers, 128-256 neurons), ResNets, various activations
2. **SNNs:** Converted from ANNs using NengoDL, LIF neurons, deployed on Loihi
3. **Online Learning:** Nengo-Gyrus computing Jacobian pseudoinverse dynamically—just 10 neurons for sub-mm accuracy!

<img src="../figures/2021/Figure2.png" alt="ANN Performance" width="700"/>

<img src="../figures/2021/Figure3.png" alt="SNN on Loihi" width="700"/>

### Results

**Accuracy:**
- ANNs & SNNs: Sub-millimeter positioning
- SNNs: Same accuracy with 10-100× fewer operations
- Online learning: Converges in ~8 seconds

**Energy Efficiency:**
- SNNs on Loihi: 10-100× less energy than ANNs
- Event-driven computation—only active neurons consume power

**Test Scenarios:**
- Free space navigation
- Single obstacle avoidance
- Multi-obstacle environments

All maintained sub-mm accuracy!

### Why This Matters

This is the **foundation paper** that:
- Proves SNNs can do real-time robotics on actual hardware
- Achieves sub-millisecond, sub-millimeter control
- Shows brain-like computation works for practical control problems
- Establishes NEF as the framework for neuromorphic robotics

The key insight: you don't need millions of neurons or expensive GPUs. Hundreds to thousands of SNNs on neuromorphic hardware can match traditional methods while being way more energy-efficient.

### Connection to Other Work

**Enables:** 
- 2022: Adaptive control with online learning
- 2024: Adaptive MPC with continuous model correction

This paper built the infrastructure—the 2022 and 2024 papers extended it to handle real-world uncertainties and complex predictive control.

---
